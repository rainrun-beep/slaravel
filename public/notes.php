<?php

/**
 * 依赖注入是从应用程序角度在描述, 控制反转是从容器的角度在描述
 * 
 * 控制反转IOC:谁控制谁,控制什么  为何是反转,哪些方面反转了
 * 谁控制谁:当然是IOC容器控制了对象,
 * 控制什么:那就是主要控制了外部资源获取(不只是对象包括比如文件等)
 * 为何是反转:因为由容器帮我们查找及注入依赖对象,对象只是被动的接收依赖对象,所以是反转
 * 哪些方面反转了:依赖对象的获取被反转了
 * 例如:所有的类都会在spring容器中登记，告诉spring你是个什么东西，你需要什么东西，然后spring会在系统运行到适当的时候，把你要的东西主动给你，同时也把你交给其他需要你的东西。所有的类的创建、销毁都由 spring来控制，也就是说控制对象生存周期的不再是引用它的对象，而是spring。对于某个具体的对象而言，以前是它控制其他对象，现在是所有对象都被spring控制，所以这叫控制反转。
 * 
 * 依赖注入 DI: 谁依赖谁, 为什么需要依赖, 谁注入谁, 注入了什么
 * 谁依赖谁:当然是应用程序依赖于IOC容器
 * 为什么需要依赖:应用程序需要IOC容器来提供对象需要的外部资源
 * 谁注入谁：很明显是IOC容器注入应用程序某个对象，应用程序依赖的对象
 * 注入了什么:就是注入某个对象所需要的外部资源(包括对象,资源,常量数据)
 * 例如:比如对象A需要操作数据库，以前我们总是要在A中自己编写代码来获得一个Connection对象，有了 spring我们就只需要告诉spring，A中需要一个Connection，至于这个Connection怎么构造，何时构造，A不需要知道。在系统运行时，spring会在适当的时候制造一个Connection，然后像打针一样，注射到A当中，这样就完成了对各个对象之间关系的控制。A需要依赖 Connection才能正常运行，而这个Connection是由spring注入到A中的，依赖注入的名字就这么来的,通过反射实现依赖注入
 * 
 * 1.依赖: 可以简单的理解，就是一个类A使用到了另一个类B， 而这种使用关系是具有偶然性的，临时性的，非常弱的，但是B类的变化会影响到A(A在b中作为形参或者直接在函数内实例化A)
 * 2.关联：关联是一种拥有的关系，表现在代码上，就是一个类包含另一个类的实例，通常表现为被关联类以类属性的形式出现在关联类的类定义中，也可以表现为关联类引用了一个类型为被关联类的全局变量，关联可以使单向的，也可以使双向的，依赖和关联的区别在于依赖是使用，关联是拥有（将A实例化作为B的属性）
 * 3.聚合：聚合是关联关系的一种，它是一种强关联关系，聚合关系是整体和个体/部分之间的关系；关联关系的两个类处于同一个层次上，而聚合关系的两个类处于不同的层次上，一个是整体，一个是个体/部分，在聚合关系中，代表个体/部分的对象有可能会被多个代表整体的对象所共享；与上面关联的代码不同之处在于构造b时必须同时构造B，也就是说B是A的不可缺少的一部分
 * 
 * mysql:
 *      连接层：判断用户名密码是否正确， 判断是否有权限登录， 创建线程，分配线程
 *      sql层： 
 *          解析器：
 *              语法解析器：判断是哪个类型，ddl,dml,query,status
 *              sql解析器：根据不同的类型生成不同的树(其中的query类型主要以where后的每一个字符来生成树)
 *          优化器：根据解析树=>选择合适的执行计划(这个计划并不是最优的)
 *              1.获取表的结构信息(字段信息, 字段类型, 存储的位置, 索引信息) 获取的信息是查询的表的信息，如果是join那就是获取两张表信息
 *              2.根据解析树进行条件过滤(主要是一些没有意义的查询1=1)
 *              3.索引信息来确定/判断执行计划(计算多个用到的索引执行计划,哪个消耗的小就是用哪个索引)
 *              4.执行计划,在根据索引以及条件等来进行过滤
 * 
 * 中继日志: 用来记录主数据库中的二进制日志， 从数据库读取中继日志，根据这个文件进行数据恢复
 * 
 * 事务日志： 
 *          重做日志: 事务已经提交了，未刷新到数据库中，数据库宕机， 在mysql重启之后会执行重做日志
 *          回滚日志：事务未提交成功，数据库宕机， mysql重启之后，不执行宕机之前的操作数据，保持数据一致性
 *                    事务回滚
 * 
 * mysql分页优化(千万级别表)
 *          select * from article limit 9999999, 10;  (执行时间37s+, 加完索引8s+)
 *          1, 可以通关子查询
 *              select * from article where id >= (select id from article limit 9999999, 1) limit 10; (执行时间7s+, 内存和cpu有影响)
 * 
 *          2, 先查询id, 再查询数据
 *              select id from article limit 9999999, 10;(执行时间7s+)
 *              select * from article where id in(加上上面的语句);(执行时间0.3s+)
 * 
 *          3, 先加索引再查询
 *              alter table article add index idx_title_url_author(title, url, author)(如果表太大生成会很慢, 千万级别表127+s);
 *              select title, url, author from article where id >= (select id from article limit 9999999, 1) limit 10; (执行时间6s+) 
 * 
 * psr-4: {Slaravel\\: src }  Slaravel命名空间所在的父级目录
 * 
 * 叶子节点就是树最下面没有子节点的节点 
 * 非叶子节点就是树下面有子节点的节点
 * 兄弟节点就是同一层的所有节点
 * 度就是这个树的深度，从根节点到叶子节点的层数
 * 
 * 叶子节点存储数据 非叶子节点存储索引 索引和数据存在同一片表空间
 * update user set uname = abc where id = 1;
 * sql对于新增是一个规则=>依赖于索引 主键索引
 * 
 * 独享: 一个表一个表空间
 * 共享: 多个表共用一个空间
 * 
 * 表空间->段空间->区->页->行
 * innodb是多个段空间组成: 
 *                          1.叶子段：索引b+tree信息
 *                          2.非叶子段：索引btree的信息
 *                          3.回滚段：回滚的数据
 *                          4.索引段：总的索引位置记录
 * 
 *                              一个段由多个区组成， 一个区有64个页，一个页大小16k, 一个页有多个行空间(行空间 数据的长度大小，实际的表数据，文件头信息等 主键索引)， 一个区大概有1mb大小，如果空间不够重新申请一个空间
 * 
 * 存储引擎中有两个部分
 * 缓存池和查询缓存不一样，缓存池操作数据就会记录一次， 查询缓存是查询之后就会记录下来，加快查询的速度，缓存池不管新增还是查询都会记录在缓存池中以链表形式，都会记录然后根据检查点存入到磁盘中，缓存池在表空间中，下一次操作就不需要去磁盘中拿
 * 1. innodb缓存池(innodb_buffer_pool)
 *          数据页:实际操作记录,对数据实际的操作记录 lru算法采用中点策略(链表形式, 最前端会是访问最频繁的数据，最后面是操作不频繁的数据，如果有新的操作记录默认插入到中间，如果频繁操作增加，会逐个删除不频繁的数据操作)，还有锁，会锁住当前的数据信息，后面的记录会继续等待
 *          索引页:记录使用索引的信息，
 * 
 * 
 * 什么是索引?
 *          索引是数据库相关优化的重要手段， 主要是单表的情况下， 索引不是万能的，不要误会使用就一定可以优化
 *          mysql中的索引类型: btree索引， hash索引，fulltext(全文索引) 一般会使用es分布式搜索引擎代替，R-tree索引
 *          索引: 主键索引：就是我们的主键
 *                唯一索引：一个唯一字段建立的索引
 *                单索引: 单个字段建立的索引
 *                联合索引: 多个字段联合建立的索引
 *                全文索引: 你真帅  你  真  帅(分成关键字) 针对于中文进行分词的搜索
 *                覆盖索引: 所有查询sql所追求的 索引效率的完美使用
 * 
 *          Btree结构: 二叉树  二分算法
 *                  是为了查询数据不管是左边还是右边都能做到平衡
 *                  对于新增而言新增的效率是会降低的，
 * 
 *                  btree是根据平衡二叉树来的，5,10,15,20,25,30,50,60,75,80,85,90(id也可以看做索引id 根据id获取对应的page在磁盘中的位置)
 *                  user
 *                  id       name              25     50    75           100  非叶子节点(节点之间叶的位置)
 *                                  5 10 15 20     30    60     80 85 90    叶子节点(存储数据)
 *                          1 2 3 4
 *                  数据不是存在非叶子节点，所有的数据存储在叶子节点，根据数据的情况进行数据计算会尽量的均衡分配，上面例子一页分配尽量四行数据，不同的页有浮动的范围=>基本的浮动范围=>浮动值=>根据最大和最小创建不同的页(上面例子一页四行，新增多量数据进行计算)
 * 
 * mysql用的b+tree结构；
 * b-tree在非叶子节点也可以保存数据，b+tree非叶子节点保存索引行记录在哪里，
 * 
 * myisam与Innodb主键索引以及普通索引之间的区别?
 *      myisam存储引擎，主键索引与普通索引都是指向数据在磁盘中的位置
 *      innodb存储引擎，主键索引指向数据在磁盘中的位置信息而普通索引则是实际的数据以及指向主键索引
 * 
 * 主键索引与普通索引之间的区别?
 *      普通索引是依赖于主键索引而存在的
 * innodb回表问题
 *      回表为什么产生? 他是如何查询数据的?
 *          一般是在innodb存储引擎下使用普通索引的情况下产生,
 *          现象:一般是在sql语句在使用普通索引查询，但是使用的索引又不满足sql查询的要求 
 *          先进入普通索引查询数据=>发现没有age字段=>回到主键索引树中=>根据主键索引的指向到磁盘中查询数据=>在进行返回(没有什么用， 反而会影响到mysql的性能)
 * 
 * 什么是覆盖索引
 *      在索引中有sql需要查询的字段列 
 * alter table t add index idx_username_sex_age(username, sex, age);
 * (1)  (1,2)  (1, 2, 3) 索引的最左匹配原则
 * select sex, age from t where sex =  and age = ;where和*都会放弃索引进行全局扫描
 * 
 * 主键索引和普通索引的区别
 * 
 * 
 * 隔离级别的实现
 *      RU(读未提交)：主要是通过重做与回滚
 *      RC(读已提交)：加排他锁,不允许其他事务读取到数据,同时也不能修改
 *      RR(可重复读): 
 *      串行化：直接加排他锁 
 * 
 * 快照创建是在事务开始的时候?
 * 还是在begin之后的select的时候
 * 对于快照读的规则：
 *      1. 对于事务中修改的数据，可以读到
 *      2. 版本未提交，不能查询 (在开启事务之后,执行修改语句,但是没有提交commit属于版本未提交)
 *      3. 版本已提交，但是在快照创建后提交不能查询到(快照创建是在begin之后的select时候，每次修改操作数据会对快照版本进行更新)
 *      4. 版本已提交，但是在快照创建前提交可以查询到
 * 
 * 事务与IO的关系
 *      连续读取: 1 2 3
 *      随机读取: 
 * mysql的优化本质上就是减少io的消耗
 * 
 * 并不是事务提交之后就把数据刷新到磁盘,日志先行
 * innodb_flush_log_at_trx_commit
 * 0 每秒写入到日志内存中(mysql 内存)，但是不会是每次事务提交都做，而是到一秒钟之后调用同步刷新到磁盘中
 * 2 每次提交时写入到os内存中, 每秒调用同步刷新到磁盘中
 * 1 每次提交时写入到os 内存中(os内存)，然后调用同步刷新到磁盘中 性能最差，因为io过多
 * 
 * 0 会将一秒之内的提交都存到log 缓存中, 然后每隔一秒钟会从缓冲池中写入到内存中，但是不会是每次事务提交都做，而是每次执行几个事务的结果， 可能会丢失一秒钟的数据
 * 1 默认参数，每提交一次事务都会触发将数据刷新到磁盘中去  数据最安全，性能最差的
 * 2 在每次事务结束后后刷新到os日志当中，再由os日志写入到磁盘中，性能居中
 * 0：在数据不是很重要的情况下，而追求的是更好的性能
 * 如果是主从: 2
 * 
 * innodb的行级锁是通过给索引项加锁实现的
 * 
 * 隔离级别-问题
 * ru(读未提交)->脏读，不可重复读，幻读
 * rc(读已提交)->不可重复读，幻读
 * rr(重复读)->幻读
 * 串行化完美解决  (隔离级别由低到高，性能由高到低)
 * 
 * 全值匹配我最爱，最左前缀要遵守
 * 带头大哥不能死，中间兄弟不能断
 * 索引列上少计算，范围之后全失效
 * Like百分写最右，覆盖索引不能写星
 * 不等空值还有or，索引失效要少用
 * VAR引号不能丢，SQL高级也不难
 * 
 * group by, order by, 子查询, 联合查询可能产生临时表
 * ? 为什么表级锁更适合于查询为主的应用
 * ? 如何避免死锁
 * ? mysql中普通索引重复率过高为什么会转换为表锁
 * 
 * 查询通过审核与销量排名前10的商品(当前店铺id为1的店铺)
 * select * from products where status = 1 and shop_id = 1 order by sold_count desc limit 0, 10;
 * 
 * 查询女性的平均月薪与客户数量
 * explain select count(*), avg(monthsalary) from customersls where gender = 0;
 * 查询不同城市的女性客户数量与平均月薪
 * explain select count(*), avg(monthsalary) from customersls where gender = 0 group by city;
 * alter table customersls add index idx_gender_city_monthsalary(gender, city, monthsalary);
 * count(*) 在innodb不会产生回表， 因为count(*)会统计id
 * 联合索引 (a, b, c) a, c也可以命中索引
 * 
 * select 
 * count(distinct yearbonus) / count(*) as year_select,
 * count(distinct monthsalary) / count(*) as mon_select,
 * count(distinct TIMESTAMPDIFF(YEAR, birthdate, CURDATE())) / count(*) as bir_select,
 * count(*) as counts
 * from customersls;
 * 越小重复几率就越大a, 越大重复几率就越小b, 建立联合索引的时候就可以按照(b, a), 按照重复率从低到高建立索引
 * 
 * 当我们使用max与group by一起是有时会出现数据不一致的问题
 * 原因: 主要是由group by 分组后显示的是第一条记录, 而max()取的是相同sid中的最大score值造成的
 * 
 * sid     cid     score
 * 01      01      80.0
 * 01      02      90.0
 * 01      03      99.0
 * group by 分组显示当前sid为01值的第一条, max会去score最多的值
 * 查询到的是 01   01   99.0  (80.0, 90.0, 99.0)
 * 有问题:SELECT sid,cid,MAX(score) as score FROM sc GROUP BY sid;
 * 
 * 改进:select a.sid, a.cid, a.score from sc as a,(select sid, max(score) as score from sc group by sid) as b where a.sid = b.sid and a.score = b.score;
 * 
 * 每次查看统计结果执行一次 实时的
 * select count(*) as count, category_id from products group by category_id order by count desc limit 0, 10;
 * 
 * 方案1: 定时任务执行脚本进行统计
 *      步骤：1, 在shell脚本中查询出需要的数据
 *            2, 将数据新增到一张统计表中
 *            3, 定时执行shell脚本
 *            4，查询统计表数据
 *            优点：占用资源小
 *            缺点：数据不实时
 * 
 * 方案2：统计问题-队列
 *          1，新增一个商品到数据库中
 *          2，数据库完成新增之后程序调用队列，插入一个任务
 *          3，执行任务，统计数据，将结果写入统计表
 *          4，查询数据
 *          优点：数据实时
 *          缺点：占用资源大，如果高并发会不断消耗资源
 * 
 * 超卖
 * 
 * 1，mysql锁机制
 *          (悲观锁)先进行商品的查询并加上一把排他锁，判断商品是否存在以及商品的库存是否是大于0的，因为在查询的时候加了排他锁，所以数据并不属于缓存查询的数据，而是磁盘中实际的，属于当前读，如果此时其他事务进行查询，会进入锁等待，直到他得到锁为止
 *          begin
 *          select * from product where id = 1 for update;
 *          if 判断库存以及商品
 *              修改库存
 *              commit
 *          else
 *              echo 商品不存在 or 库存不足
 *              rollback
 * 乐观锁适用于写比较少的情况下(多读场景)，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量
 * 
 * 悲观锁适用于读比较少的情况下(多写场景)，如果是多写的情况，一般会经常产生冲突，如果使用乐观锁，这就会导致上层应用会不断的进行retry，这样反倒降低了性能，所以一般多写的场景下用悲观锁就比较适合
 *  
 * binary log:
 *      二进制日志包含描述数据库更改的“事件”，例如表创建操作或对表数据的更改。 
 *      它还包含可能已进行更改的语句的事件（例如，不匹配任何行的DELETE），除非使用基于行的日志记录。 
 *      二进制日志还包含有关每个语句获取更新数据的时间长度的信息。 
 *      二进制日志有两个重要目的：用于复制
 *              某些数据恢复操作需要使用二进制日志。
 *              备份恢复后，将重新执行备份后记录的二进制日志中的事件。 这些事件使数据库从备份点更新。
 *      二进制日志不用于不修改数据的SELECT或SHOW等语句
 * 
 * ib_logfile(relog)
 *      一组文件，通常名为ib_logfile0和ib_logfile1，构成重做日志。 有时也称为日志组。 
 *      这些文件记录了尝试更改InnoDB表中数据的语句。 
 *      在崩溃后启动时，会自动重播这些语句以更正由不完整事务写入的数据。
 *      此数据不能用于手动恢复; 对于该类型的操作，请使用二进制日志。
 * 
 * 2，redis队列
 *         1，设置一个长度为10的队列
 *         2，每一个用户买了弹出一个
 * 
 * join 就像 
 *          for 
 *              for
 * 1, 小的表去驱动大的表
 * 2, 关联字段尽量是索引字段
 * 3, join buffer 256kb
 * 
 * 1，表的大小
 * 2，根据条件看扫描的数据量
 * 3，条件以及关联字段
 * 
 * 子查询
 * mysql 5.6开始 优化  join
 * max与group分组 就是子查询->join
 * >= 3张表
 */

/**
 * tcp 防止丢包
 * udp
 * 1. tcp提供的是面向连接的，可靠的数据流传输；udp提供的是非面向连接的，不可靠的数据流传输，tcp提供可靠的服务，通过tcp连接传送的数据，无差错，不丢失，不重复，按序到达；udp尽最大努力交付，既不保证可靠交付
 * 2. tcp面向字节流； udp面向报文
 * 3. tcp连接只能是点到点的；udp支持一对一，一对多，多对一和多对多的交互通信
 * 4. udp具有较好的实效性，工作效率比tcp高，适用于对高速传输和实时性有较高的通信或广播通信
 * 例如:打电话udp   短信tcp
 * tcp将数据一段一段的发送，一直等到接收成功 udp是将所有数据都打包发送，不管接收到没有，丢出去就行了，
 * udp就像渣男， tcp像暖男，
 * 
 * tcp三次握手(连接) 每次使用tcp连接都会使用三次握手
 * 客户端发送数据包， 服务端接收数据包重新组装数据包然后发送给客户端，
 * 第一次握手:客户端发送网络包，服务端收到了，这样服务端就能得出结论，客户端的发送能力，服务端的接受能力是正常的，
 * 第二次握手:服务端发包，客户端收到了，这样客户端就能得到结论：服务端的接收，发送能力，客户端的接收，发送能力是正常的，不过此时服务器并不能确认客户端的接受能力是否正常，
 * 第三次握手:客户端发包，服务端收到了，这样服务端就能得到结论:客户端的接收，发送能力正常，服务器自己的发送，接收能力也正常
 * 
 * tcp四次握手(断开)
 * 第一次，先发起请求
 * 第二次，服务端确认
 * 第三次，服务端断开连接
 * 第四次，针对服务端的确认应答(对于服务端已经不重要了)
 * 
 * 当服务端接收到fin报文时，不会立即关闭socket，所以只能先回复一个ack报文，告诉客户端，'你发的fin报文我收到了'，只有等到客户端接收到服务端所有的报文都发送完了，客户端才能发送fin报文，因此不能一起发送，故需要四次挥手
 * 第四次是减少等待时间，所以也是需要的，
 * 
 * tcp粘包问题
 * tcp在发送数据的时候因为存在数据缓存的关系，对于数据在发送的时候在短时间内如果连续发送很多小的数据的时候就会有可能一次性一起发送，还有就是对于大的数据就会分开持续发送多次
 * 
 * 粘包处理方案
 * 1.特殊字符
 *     根据客户端与服务端相互约定的特殊的符号，对接收的数据进行分割处理
 * 2.固定包头+包体协议(主流)
 *     通过在数据传输之后会在tcp的数据包中携带上数据的长度，然后服务端就可以根据这个长度，对于数据进行截取
 * 123->pack N/n  包头
 * N占4个字节，n占2个字节
 * 1(int)=>4字节; 1字节(byte)=>8bit(位);
 * 
 * socket就是linux留下的资源流，客户端向socket写入信息, 服务端读取信息，服务端写入信息，客户端读取socket信息 资源文件fd => id存入到socket，
 * 
 * Redis中list类型结构实现主要是依据什么? 
 *      1.链表
 *           [prev][value][next] -> [prev][value][next]
 *      2.压缩列表
 * list应用场景: 
 *      超卖  (高并发  恶意请求)？
 *      排行榜
 *      分页
 * 
 * 
 * redis中5种数据结构及使用场景
 *      1.字符串
 *          字符串类型是redis最基础的数据结构，首先键是字符串类型，而且其他几种结构都是在字符串类型基础上构建的，
 *          所以字符串类型能为其他四种数据结构的学习尊定基础。
 *          字符串类型实际上可以是字符串
 *          (简单的字符串、复杂的字符串(xml、json)、数字(整数、浮点数)、二进制(图片、音频、视频))，
 *          但最大不能超过512M。
 *        使用场景
 *          缓存功能：字符串最经典的使用场景，redis最为缓存层，Mysql作为储存层，绝大部分请求数据都是
 *                   redis中获取，由于redis具有支撑高并发特性，所以缓存通常能起到加速读写和降低 后端压力的作用。
 *                   （redis为何具备支撑高并发的特性，下次文章讲解）。
 *          计数器：许多运用都会使用redis作为计数的基础工具，他可以实现快速计数、查询缓存的功能，
 *                   同时数据可以一步落地到其他的数据源。
 *                  如：视频播放数系统就是使用redis作为视频播放数计数的基础组件。
 *          共享session：出于负载均衡的考虑，分布式服务会将用户信息的访问均衡到不同服务器上，
 *                   用户刷新一次访问可能会需要重新登录，为避免这个问题可以用redis将用户session集中管理，
 *                   在这种模式下只要保证redis的高可用和扩展性的，每次获取用户更新或查询登录信息
 *                   都直接从redis中集中获取。
 *          限速：处于安全考虑，每次进行登录时让用户输入手机验证码，为了短信接口不被频繁访问，
 *                   会限制用户每分钟获取验证码的频率。(setex)
 * 
 *      2.哈希
 *          在redis中哈希类型是指键本身又是一种键值对结构，如 value={{field1,value1},......{fieldN,valueN}} 
 *        使用场景
 *          哈希结构相对于字符串序列化缓存信息更加直观，并且在更新操作上更加便捷。
 *          所以常常用于**用户信息**等管理，但是哈希类型和关系型数据库有所不同，哈希类型是稀疏的，
 *          而关系型数据库是完全结构化的，关系型数据库可以做复杂的关系查询，而redis去模拟关系型复杂查询
 *          开发困难，维护成本高。
 * 
 *      3.列表
 *          列表类型是用来储存多个有序的字符串，列表中的每个字符串成为元素（element）,一个列表最多可以储存
 *          2的32次方-1个元素，在redis中，可以队列表两端插入（pubsh）和弹出（pop），还可以获取指定范围的元素
 *          列表、获取指定索引下表的元素等，列表是一种比较灵活的数据结构，它可以充当栈和队列的角色，
 *          在实际开发中有很多应用场景。
 *          优点：
 *               1.列表的元素是有序的，这就意味着可以通过索引下标获取某个或某个范围内的元素列表。
 *               2.列表内的元素是可以重复的。
 * 
 *          使用场景:
 *               1.redis的lpush+brpop命令组合即可实现阻塞队列,生产者客户端是用lpush从列表左侧插入元素,
 *               多个消费者客户端使用brpop(命令移除并获取列表的最后一个元素,如果列表没有元素会阻塞列表直到等待超时
 *               或发现可弹出元素)命令阻塞时的“抢”列表尾部的元素,多个客户端保证了消费的负载均衡和高可用性
 * 
 *          消息队列模型:
 *              文章列表:每个用户都有属于自己的文章列表,现在需要分页展示文章列表,此时可以考虑使用列表,
 *              列表不但有序同时支持按照索引范围获取元素
 * 
 *          使用列表技巧:
 *              lpush+lpop = stack(栈)
 *              lpush+rpop = queue(队列)
 *              lpush+ltrim = capped collection(有限集合)
 *              lpush+brpop = message queue(消息队列)
 * 
 *          4.集合
 *              1.集合类型也是用来保存多个字符串的元素,但和列表不同的是集合中不允许有重复的元素,并且集合中的元素是
 *              无序的,不能通过索引下标获取元素,redis除了支持集合内的增删改查,同时还支持多个集合取交集,并集,差集,
 *              并合理的使用好集合类型,能在实际开发中解决很多实际问题
 * 
 *          使用场景:
 *              标签(tag): 集合类型比较典型的使用场景,如一个用户对娱乐,体育比较感兴趣,另一个可能对新闻感兴趣,
 *              这些兴趣就是标签,有了这些数据就可以得到同一个标签的人,以及用户的共同爱好的标签,这些数据对于用户
 *              体验以及增加用户粘度比较重要.
 *              (用户和标签的关系维护应该放在一个事物内执行,防止部分命令失败造成数据不一致)
 * 
 *          sadd = tagging(标签)
 *          spop/srandmember = random item(生成随机数,比如抽奖)
 *          sadd+sinter = social graph(社交需求), (返回给定所有集合的交集)
 * 
 *          5.有序集合
 *              有序集合和集合有着必然的联系,他保留了集合不能有重复成员的特性,但不同的是,有序集合中的元素是可以
 *              排序的,但是它和列表的使用索引下标作为排序依据,不同的是它给每个元素设置一个分数,作为排序的依据. 
 *              (有序集合中的元素不可以重复,但是csore可以重复,就和一个班里的同学学号不能重复,但考试成绩可以相同)
 * 
 *          列表,集合,有序集合三者的异同点
 * 
 *          使用场景:
 *              排行榜:有序集合经典实用场景.例如视频网站需要对用户上传的视频做排行榜,
 *              榜单维护可能是多方面: 按照时间,按照播放量,按照获得的咱数等
 *          
 *          
 *          
 *          
 *          
 * 
 * 
 * 
 * 
 * redis乐观锁 
 *      watch监控
 *          redis watch命令用于监视一个或多个key, 如果在事务执行之前这个(或这些)key被其他命令所改动，
 *              那么事务将被打断(执行最先exec事务, 抛弃后面的)
 *      流程:
 *          1.监控key
 *          2.开启当前redis会话事务状态
 *          3.命令入队,同时redis服务会对执行的命令进行判断,是否为事务命令,如果是直接执行,否则加入事务命令队列
 *          4.执行事务,同时会判断监控的key是否发生变化,如果有直接打断事务,否则执行并取消key的监控,以及返回命令执行的结果
 * 
 * redis为什么使用消息队列
 *          1.削峰,减少响应时间
 *          2.降低系统耦合性
 * 
 *      stream的类型
 *          redis stream主要用于消息队列(MQ, message queue), redis本身是有一个redis发布订阅(pub/sub)来实现消息队列的功能，
 *          但它有个缺点就是消息无法持久化,如果出现网络断开,redis宕机等,消息就会被丢弃,
 * 
 *          发布了一个消息，下了单，库存里面可能就少了一个，还需要及时补充采购， 不同的消费者可以是不同业务，但是可以
 *          是消费同一个消息, 一个消费组里面是不会出现消费者消费同一个消息的
 * 
 * 
 * 以下的方式不发确定消息是否被正确消费了
 * redis实现消息队列
 *          1.redis list类型实现
 *              使用redis的lpush/rpop(rpush/lpop)命令简单实现左近右出或右进左出的list列表。然后需要开启一个线程任务
 *              或者定时任务或者轮询方式,不停的调用rpop方法查看list中是否有待处理消息
 *          2.发布/订阅
 *              生产者和消费者通过相同的一个信道进行交互,信道其实也就是队列,通常会有多个消费者,多个消费者订阅同一个信道,
 *              当生产者向信道发布消息时,该信道会立即将消息逐一发布给每个消费者,所以该信道对于消费者是发散的信道,
 *              每个消费者都可以得到相同的消息,典型的一对多的关系
 * 
 * 
 * 
 * io五大网络模式
 *          1.阻塞io模型
 *              最传统的一种io模型, 即在读写数据过程中会发生阻塞现象
 * 
 *              当用户线程发出io请求之后,内核会去查看数据是否就绪, 如果没有就绪就会等待数据就绪, 而用户线程就会处
 *              于阻塞状态, 用户线程交出cpu, 当数据就绪之后,内核会将数据拷贝到用户线程, 并返回结果给用户线程, 用户
 *              线程才接触block状态
 * 
 *          2.非阻塞io模型
 *              当用户线程发起一个read操作后,并不需要等待,而是马上就得到了一个结果,如果结果是一个error时,它就知道数
 *              据还没有准备好,于是它可以再次发送read操作,一旦内核中的数据准备好了,并且又再次收到了用户线程的请求,那
 *              么它马上就将数据拷贝到了用户线程,然后返回,所以事实上,在非阻塞io模型中,用户线程需要不断地询问内核
 *              数据是否就绪, 也就说非阻塞io不会交出cpu, 而会一直占用cpu
 * 
 *          3.多路复用io模型
 *              在多路复用IO模型中，会有一个线程不断去轮询多个socket的状态，只有当socket真正有读写事件时，才真正调用
 *              实际的IO读写操作。因为在多路复用IO模型中，只需要使用一个线程就可以管理多个socket，系统不需要建立
 *              新的进程或者线程，也不必维护这些线程和进程，并且只有在真正有socket读写事件进行时，才会使用IO资源，
 *              所以它大大减少了资源占用。
 * 
 *          4.信号驱动io模型
 *              在信号驱动IO模型中，当用户线程发起一个IO请求操作，会给对应的socket注册一个信号函数，然后用户线程
 *              会继续执行，当内核数据就绪时会发送一个信号给用户线程，用户线程接收到信号之后，便在信号函数中调用
 *              IO读写操作来进行实际的IO请求操作。
 * 
 *          5.异步io模型
 *              异步IO模型才是最理想的IO模型，在异步IO模型中，当用户线程发起read操作之后，立刻就可以开始去做
 *              其它的事。而另一方面，从内核的角度，当它收到一个asynchronous read之后，它会立刻返回，说明read
 *              请求已经成功发起了，因此不会对用户线程产生任何block。然后，内核会等待数据准备完成，然后将数据拷
 *              贝到用户线程，当这一切都完成之后，内核会给用户线程发送一个信号，告诉它read操作完成了。也就说用户
 *              线程完全不需要知道实际的整个IO操作是如何进行的，只需要先发起一个请求，当接收内核返回的成功信号时
 *              表示IO操作已经完成，可以直接去使用数据了。　
 *              也就说在异步IO模型中，IO操作的两个阶段都不会阻塞用户线程，这两个阶段都是由内核自动完成，然后发送
 *              一个信号告知用户线程操作已完成。用户线程中不需要再次调用IO函数进行具体的读写。这点是和信号驱动模
 *              型有所不同的，在信号驱动模型中，当用户线程接收到信号表示数据已经就绪，然后需要用户线程调用IO函数
 *              进行实际的读写操作；而在异步IO模型中，收到信号表示IO操作已经完成，不需要再在用户线程中调用iO函数
 *              进行实际的读写操作。
 * 
 *      系统内核操作进程的创建/销毁
 *      用户空间创建协程
 * 
 *      同步与异步
 *              实际上同步与异步是针对应用程序与内核的交互而言的。同步过程中进程触发IO操作并等待或者轮询的
 *              去查看IO操作是否完成。异步过程中进程触发IO操作以后，直接返回，做自己的事情，IO交给内核来
 *              处理，完成后内核通知进程IO完成。
 * 
 *              阻塞IO，指的是需要内核IO操作彻底完成后，才返回到用户空间执行用户的操作。阻塞指的是用户空间程序的执
 *              行状态。传统的IO模型都是同步阻塞IO。再Java中，默认创建的socket都是阻塞的。
 *              非阻塞IO，指的是用户空间的程序不需要等待内核IO操作彻底完成，可以立即返回用户空间执行用户操作，
 *              即处于非阻塞的状态，与此同时内核会立即返回给用户一个状态值。
 *              简单来说：阻塞是指用户空间（调用线程）一直在等待，而不能干别的事情；非阻塞是指用户空间（调用线程）
 *              拿到内核返回的状态值就返回自己的空间，IO操作可以干就干，不可以干，就去干别的事情。
 * 
 *      队列先进先出, 栈先进后出
 *              
 *              
 *      
 */
